{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tip-colab-파일저장및업로드-colab",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/whkwls2653/Emotion-Recognition/blob/main/cogmen_feature_foramt19.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "7-JR7WQ5O70X",
        "outputId": "1c17f26e-0e36-411f-b1f3-afa7dc42c4db",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import pandas as pd\n",
        "import os\n",
        "import pickle\n",
        "from tqdm import tqdm\n",
        "annotation_root= '/content/gdrive/MyDrive/emotion_recognition/dataset/KEMDy19/annotation'\n",
        "txt_label_zip_toteval_root='/content/gdrive/MyDrive/emotion_recognition/dataset/2019cogmen_format_.pkl'\n",
        "ambig_annotation=0\n",
        "no_file=0\n",
        "## formating features dim 9 list\n",
        "\n",
        "features=[]\n",
        "sess_ids=[]\n",
        "sess_speakers=dict()\n",
        "sess_labels=dict()\n",
        "sess_text=dict()\n",
        "sess_audio=dict()\n",
        "sess_visual=dict()\n",
        "sess_sentence=dict()\n",
        "sess_train=[]\n",
        "sess_test=[]\n",
        "\n",
        "if os.path.isfile(txt_label_zip_toteval_root):\n",
        "  with open(txt_label_zip_toteval_root,'rb') as f:\n",
        "    allfile_datalist=pickle.load(f)\n",
        "else:\n",
        "  allfile_datalist=[]\n",
        "  for i, annotation in tqdm(enumerate(os.listdir(annotation_root))):\n",
        "    all_txts=[]\n",
        "    print('annotaion file : (%d / %d)'%(i,len(os.listdir(annotation_root))))\n",
        "    session_file = pd.read_csv(os.path.join(annotation_root,annotation)) \n",
        "    # print(session_file) \n",
        "    segments=session_file['Segment ID']\n",
        "    session_file.loc[(session_file['Total Evaluation'] == \"fear\"), 'Total Evaluation'] = 0  #공포 => 0\n",
        "    session_file.loc[(session_file['Total Evaluation'] == \"surprise\"), 'Total Evaluation'] = 1  #놀람 => 1\n",
        "    session_file.loc[(session_file['Total Evaluation'] == \"angry\"), 'Total Evaluation'] = 2  #분노 => 2\n",
        "    session_file.loc[(session_file['Total Evaluation'] == \"sad\"), 'Total Evaluation'] = 3  #슬픔 => 3\n",
        "    session_file.loc[(session_file['Total Evaluation'] == \"neutral\"), 'Total Evaluation'] = 4  #중립 => 4\n",
        "    session_file.loc[(session_file['Total Evaluation'] == \"happy\"), 'Total Evaluation'] = 5  #행복 => 5\n",
        "    session_file.loc[(session_file['Total Evaluation'] == \"disgust\"), 'Total Evaluation'] = 6  #혐오 => 6\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    # print(segments)\n",
        "    ##segments == utterence  \n",
        "    for j in range(1,len(segments)):\n",
        "       #index starts from 1\n",
        "      label= session_file['Total Evaluation'][j]\n",
        "      if type(label) !=int:\n",
        "        ambig_annotation+=1\n",
        "        continue\n",
        "      f_name=segments[j]\n",
        "      gender=f_name.split('_')[-1][0]\n",
        "      \n",
        "      # print(\"f_name:\",f_name)\n",
        "      sess_num=f_name.split('_')[0][-2:]\n",
        "      sc_pro_num=f_name.split('_')[0]+'_'+f_name.split('_')[1]\n",
        "\n",
        "      ###texts\n",
        "      file_loc='/content/gdrive/MyDrive/emotion_recognition/dataset/KEMDy19/wav/Session%s/%s/%s.txt'%(sess_num,sc_pro_num,f_name)\n",
        "      # print(file_loc)\n",
        "      if not os.path.isfile(file_loc):\n",
        "        print(\"no file location :\",file_loc)\n",
        "        no_file+=1\n",
        "        continue\n",
        "      with open(file_loc) as f:\n",
        "        lines = f.readlines()[0]\n",
        "      if '\\n' in lines or'/'in lines :\n",
        "        # print('lines',lines)\n",
        "        new_words=lines.replace('\\n','')\n",
        "        # print('new_words',new_words)\n",
        "        new_words=new_words.replace('o/','')\n",
        "        new_words=new_words.replace('I/','')\n",
        "        new_words=new_words.replace('b/','')\n",
        "        new_words=new_words.replace('u/','')\n",
        "        new_words=new_words.replace('l/','')\n",
        "        new_words=new_words.replace('n/','')\n",
        "        new_words=new_words.replace('N/','')\n",
        "        new_words=new_words.replace('s/','')\n",
        "        new_words=new_words.replace('c/','')\n",
        "        new_words=new_words.replace('(','')\n",
        "        new_words=new_words.replace(')','')\n",
        "        new_words=new_words.replace('+',' ')\n",
        "        lines=new_words\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "     \n",
        "      if sc_pro_num not in sess_ids:\n",
        "        sess_ids.append(sc_pro_num)\n",
        "        sess_speakers[sc_pro_num]=[]\n",
        "        sess_labels[sc_pro_num]=[]\n",
        "        sess_text[sc_pro_num]=[]\n",
        "        sess_audio[sc_pro_num]=[]\n",
        "        sess_visual[sc_pro_num]=[]\n",
        "        sess_sentence[sc_pro_num]=[] \n",
        "        if sess_num ==19 or sess_num==20:\n",
        "          sess_test.append(sc_pro_num)\n",
        "        else:\n",
        "          sess_train.append(sc_pro_num)\n",
        "       \n",
        "      sess_labels[sc_pro_num].append(label)\n",
        "      sess_speakers[sc_pro_num].append(gender)\n",
        "      # print('labels',labels,type(labels))\n",
        "      # print('stcs',lines,type(lines))\n",
        "      # sess_labels[sc_pro_num]=file_labels\n",
        "      sess_sentence[sc_pro_num].append(lines)\n",
        "      \n",
        "      # print('1 file ends')\n",
        "      \n",
        "      # print(\"ids\",sess_ids)\n",
        "      # print(\"speakers\",sess_speakers)\n",
        "      # print(\"labels\",sess_labels)\n",
        "      # print(\"text\",sess_text)\n",
        "      # print(\"audio\",sess_audio)\n",
        "      # print(\"visual\",sess_visual)\n",
        "      # print(\"stcs\",sess_sentence)\n",
        "      # print(\"tr\",sess_train)\n",
        "      # print(\"te\",sess_test)\n",
        "      # print(sess_num,sc_pro_num)\n",
        "      \n",
        "    #  /content/gdrive/MyDrive/감정인식 대회/데이터셋/KEMDy19/wav/Session01/Sess01_script01/Sess01_script01_F001.txt\n",
        "      \n",
        "      # print(all_txts) \n",
        "  # print(\"ids\",sess_ids)\n",
        "  # print(\"speakers\",sess_speakers)\n",
        "  # print(\"labels\",sess_labels)\n",
        "  # print(\"text\",sess_text)\n",
        "  # print(\"audio\",sess_audio)\n",
        "  # print(\"visual\",sess_visual)\n",
        "  # print(\"stcs\",sess_sentence)\n",
        "  # print(\"tr\",sess_train)\n",
        "  # print(\"te\",sess_test)\n",
        "  \n",
        "  features.append(sess_ids)\n",
        "  features.append(sess_speakers)\n",
        "  features.append(sess_labels)\n",
        "  features.append(sess_text)\n",
        "  features.append(sess_audio)\n",
        "  features.append(sess_visual)\n",
        "  features.append(sess_sentence)\n",
        "  features.append(sess_train)\n",
        "  features.append(sess_test)\n",
        "  \n",
        "  # print(features)\n",
        "  with open(txt_label_zip_toteval_root,'wb') as f:\n",
        "    pickle.dump(features,f)\n",
        "# print(\"data_list length :\",len(data_list))\n",
        "# print(\"sample : \",data_list[0])\n",
        "print('ambig_annotation:',ambig_annotation)  \n",
        "print('no_file',no_file)  \n",
        "# print(len(all_txts))\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "B48fHZNM9D1N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(allfile_datalist)\n",
        "print(len(allfile_datalist))"
      ],
      "metadata": {
        "id": "Dx3UkJnTju3I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(features[1]['Sess01_script03']))\n",
        "print(len(features[2]['Sess01_script03']))\n",
        "print(len(features[6]['Sess01_script03']))\n",
        "print(len(features[7]))\n",
        "\n",
        "# for i in range(10):\n",
        "#   print(len(features[i]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QDHq7JjS7dJv",
        "outputId": "2d38f17c-9b47-4f51-ed6c-94370f04ed03"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30\n",
            "30\n",
            "30\n",
            "10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a=dict()\n",
        "a['sess1']=[]\n",
        "a['sess1'].append(3)\n",
        "print(a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VqIS7nLjjI6Z",
        "outputId": "cca4978c-af30-4bdb-eaeb-e3e411190e5d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'sess1': [3]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LuspU6xca-Ym"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}