{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tip-colab-파일저장및업로드-colab",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/whkwls2653/Emotion-Recognition/blob/main/cogmen_feature_foramt19.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "7-JR7WQ5O70X",
        "outputId": "1c17f26e-0e36-411f-b1f3-afa7dc42c4db",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import pandas as pd\n",
        "import os\n",
        "import pickle\n",
        "from tqdm import tqdm\n",
        "annotation_root= '/content/gdrive/MyDrive/emotion_recognition/dataset/KEMDy19/annotation'\n",
        "txt_label_zip_toteval_root='/content/gdrive/MyDrive/emotion_recognition/dataset/2019cogmen_format__.pkl'\n",
        "ambig_annotation=0\n",
        "no_file=0\n",
        "## formating features dim 9 list\n",
        "\n",
        "features=[]\n",
        "sess_ids=[]\n",
        "sess_speakers=dict()\n",
        "sess_labels=dict()\n",
        "sess_text=dict()\n",
        "sess_audio=dict()\n",
        "sess_visual=dict()\n",
        "sess_sentence=dict()\n",
        "sess_dir=dict()\n",
        "sess_train=[]\n",
        "sess_test=[]\n",
        "\n",
        "if os.path.isfile(txt_label_zip_toteval_root):\n",
        "  with open(txt_label_zip_toteval_root,'rb') as f:\n",
        "    features=pickle.load(f)\n",
        "else:\n",
        "  \n",
        "  for i, annotation in tqdm(enumerate(os.listdir(annotation_root))):\n",
        "    all_txts=[]\n",
        "    print('annotaion file : (%d / %d)'%(i,len(os.listdir(annotation_root))))\n",
        "    session_file = pd.read_csv(os.path.join(annotation_root,annotation)) \n",
        "    # print(session_file) \n",
        "    segments=session_file['Segment ID']\n",
        "    session_file.loc[(session_file['Total Evaluation'] == \"fear\"), 'Total Evaluation'] = 0  #공포 => 0\n",
        "    session_file.loc[(session_file['Total Evaluation'] == \"surprise\"), 'Total Evaluation'] = 1  #놀람 => 1\n",
        "    session_file.loc[(session_file['Total Evaluation'] == \"angry\"), 'Total Evaluation'] = 2  #분노 => 2\n",
        "    session_file.loc[(session_file['Total Evaluation'] == \"sad\"), 'Total Evaluation'] = 3  #슬픔 => 3\n",
        "    session_file.loc[(session_file['Total Evaluation'] == \"neutral\"), 'Total Evaluation'] = 4  #중립 => 4\n",
        "    session_file.loc[(session_file['Total Evaluation'] == \"happy\"), 'Total Evaluation'] = 5  #행복 => 5\n",
        "    session_file.loc[(session_file['Total Evaluation'] == \"disgust\"), 'Total Evaluation'] = 6  #혐오 => 6\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    # print(segments)\n",
        "    ##segments == utterence  \n",
        "    for j in range(1,len(segments)):\n",
        "       #index starts from 1\n",
        "      label= session_file['Total Evaluation'][j]\n",
        "      if type(label) !=int:\n",
        "        ambig_annotation+=1\n",
        "        continue\n",
        "      f_name=segments[j]\n",
        "      gender=f_name.split('_')[-1][0]\n",
        "      \n",
        "      # print(\"f_name:\",f_name)\n",
        "      sess_num=f_name.split('_')[0][-2:]\n",
        "      sc_pro_num=f_name.split('_')[0]+'_'+f_name.split('_')[1]\n",
        "\n",
        "      ###texts\n",
        "      file_loc='/content/gdrive/MyDrive/emotion_recognition/dataset/KEMDy19/wav/Session%s/%s/%s.txt'%(sess_num,sc_pro_num,f_name)\n",
        "      # print(file_loc)\n",
        "      if not os.path.isfile(file_loc):\n",
        "        print(\"no file location :\",file_loc)\n",
        "        no_file+=1\n",
        "        continue\n",
        "      with open(file_loc) as f:\n",
        "        lines = f.readlines()[0]\n",
        "      if '\\n' in lines or'/'in lines :\n",
        "        # print('lines',lines)\n",
        "        new_words=lines.replace('\\n','')\n",
        "        # print('new_words',new_words)\n",
        "        new_words=new_words.replace('o/','')\n",
        "        new_words=new_words.replace('I/','')\n",
        "        new_words=new_words.replace('b/','')\n",
        "        new_words=new_words.replace('u/','')\n",
        "        new_words=new_words.replace('l/','')\n",
        "        new_words=new_words.replace('n/','')\n",
        "        new_words=new_words.replace('N/','')\n",
        "        new_words=new_words.replace('s/','')\n",
        "        new_words=new_words.replace('c/','')\n",
        "        new_words=new_words.replace('(','')\n",
        "        new_words=new_words.replace(')','')\n",
        "        new_words=new_words.replace('+',' ')\n",
        "        lines=new_words\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "     \n",
        "      if sc_pro_num not in sess_ids:\n",
        "        sess_ids.append(sc_pro_num)\n",
        "        sess_speakers[sc_pro_num]=[]\n",
        "        sess_labels[sc_pro_num]=[]\n",
        "        sess_text[sc_pro_num]=[]\n",
        "        sess_audio[sc_pro_num]=[]\n",
        "        sess_visual[sc_pro_num]=[]\n",
        "        sess_sentence[sc_pro_num]=[] \n",
        "        sess_dir[sc_pro_num]=[]\n",
        "        if int(sess_num) ==19 or int(sess_num)==20:\n",
        "          sess_test.append(sc_pro_num)\n",
        "        else:\n",
        "          sess_train.append(sc_pro_num)\n",
        "\n",
        "      sess_labels[sc_pro_num].append(label)\n",
        "      sess_speakers[sc_pro_num].append(gender)\n",
        "      sess_dir[sc_pro_num].append(f_name)\n",
        "      # print('labels',labels,type(labels))\n",
        "      # print('stcs',lines,type(lines))\n",
        "      # sess_labels[sc_pro_num]=file_labels\n",
        "      sess_sentence[sc_pro_num].append(lines)\n",
        "      \n",
        "      # print('1 file ends')\n",
        "      \n",
        "      # print(\"ids\",sess_ids)\n",
        "      # print(\"speakers\",sess_speakers)\n",
        "      # print(\"labels\",sess_labels)\n",
        "      # print(\"text\",sess_text)\n",
        "      # print(\"audio\",sess_audio)\n",
        "      # print(\"visual\",sess_visual)\n",
        "      # print(\"stcs\",sess_sentence)\n",
        "      # print(\"tr\",sess_train)\n",
        "      # print(\"te\",sess_test)\n",
        "      # print(sess_num,sc_pro_num)\n",
        "      \n",
        "    #  /content/gdrive/MyDrive/감정인식 대회/데이터셋/KEMDy19/wav/Session01/Sess01_script01/Sess01_script01_F001.txt\n",
        "      \n",
        "      # print(all_txts) \n",
        "  # print(\"ids\",sess_ids)\n",
        "  # print(\"speakers\",sess_speakers)\n",
        "  # print(\"labels\",sess_labels)\n",
        "  # print(\"text\",sess_text)\n",
        "  # print(\"audio\",sess_audio)\n",
        "  # print(\"visual\",sess_visual)\n",
        "  # print(\"stcs\",sess_sentence)\n",
        "  # print(\"tr\",sess_train)\n",
        "  # print(\"te\",sess_test)\n",
        "  \n",
        "  features.append(sess_ids)\n",
        "  features.append(sess_speakers)\n",
        "  features.append(sess_labels)\n",
        "  features.append(sess_text)\n",
        "  features.append(sess_audio)\n",
        "  features.append(sess_visual)\n",
        "  features.append(sess_sentence)\n",
        "  features.append(sess_train)\n",
        "  features.append(sess_test)\n",
        "  features.append(sess_dir)\n",
        "  # print(features)\n",
        "  with open(txt_label_zip_toteval_root,'wb') as f:\n",
        "    pickle.dump(features,f)\n",
        "# print(\"data_list length :\",len(data_list))\n",
        "# print(\"sample : \",data_list[0])\n",
        "print('ambig_annotation:',ambig_annotation)  \n",
        "print('no_file',no_file)  \n",
        "# print(len(all_txts))\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "B48fHZNM9D1N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "txt_label_zip_toteval_root='/content/gdrive/MyDrive/emotion_recognition/dataset/2019cogmen_format__.pkl'\n",
        "\n",
        "if os.path.isfile(txt_label_zip_toteval_root):\n",
        "  with open(txt_label_zip_toteval_root,'rb') as f:\n",
        "    features=pickle.load(f)"
      ],
      "metadata": {
        "id": "Dx3UkJnTju3I"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(features[0])\n",
        "print((features[9]))\n",
        "print(len(features[1]['Sess03_script01']))\n",
        "print(len(features[2]['Sess03_script01']))\n",
        "print(len(features[6]['Sess03_script01']))\n",
        "print(len(features[7]))\n",
        "print(sorted(features[9]))\n",
        "# for i in range(10):\n",
        "#   print(len(features[i]))"
      ],
      "metadata": {
        "id": "QDHq7JjS7dJv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install transformers\n",
        "!pip install sklearn\n",
        "!pip install scipy\n",
        "!pip install pandas\n",
        "\n",
        "!pip install audtorch"
      ],
      "metadata": {
        "id": "VqIS7nLjjI6Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/gdrive/MyDrive/emotion_recognition/2022reference/\n",
        "\n",
        "!python multimodal_feature_extractor_cogmen.py"
      ],
      "metadata": {
        "id": "LuspU6xca-Ym",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5475e5dd-3431-4ed4-f6e2-e24fc506c39a"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/emotion_recognition/2022reference\n",
            "2023-04-04 14:21:20.056156: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "device: cpu\n",
            "1\n",
            "2\n",
            "Some weights of the model checkpoint at facebook/wav2vec2-base-960h were not used when initializing Wav2Vec2Model: ['lm_head.bias', 'lm_head.weight']\n",
            "- This IS expected if you are initializing Wav2Vec2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing Wav2Vec2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "[103, 225, 287, 366, 451, 546, 607, 697, 783, 914, 1036, 1120, 1234, 1340, 1409, 1464, 1639, 1739, 1824, 1904, 2022, 2082, 2210, 2314, 2390, 2475, 2534, 2619, 2705, 2842, 2920, 3005, 3102, 3222, 3332, 3392, 3477, 3634, 3725, 3805, 3943, 4049, 4132, 4216, 4281, 4389, 4487, 4616, 4715, 4807, 4918, 5020, 5108, 5167, 5239, 5357, 5453, 5540, 5630, 5834, 5935, 6057, 6132, 6186, 6282, 6365, 6443, 6529, 6615, 6760, 6857, 6917, 6990, 7074, 7198, 7291, 7460, 7542, 7649, 7764, 7823, 7921, 8035, 8122, 8194, 8317, 8417, 8478, 8626, 8707, 8820, 8919, 9004, 9104, 9180, 9240, 9416, 9530, 9633, 9693, 9805, 9906, 10003, 10089, 10178, 10239, 10401, 10460, 10548, 10645, 10766, 10836, 10895, 10980, 11077, 11187, 11264, 11333, 11472, 11559, 11649, 11736, 11803, 11862, 11966, 12087, 12194, 12281, 12407, 12499, 12560, 12642, 12733, 12852, 12949, 13022, 13146, 13222, 13289, 13371, 13454, 13561, 13683, 13744, 13817, 13919, 14086, 14154, 14259, 14341, 14436, 14558, 14629, 14685, 14773, 14881, 14981, 15067, 15176, 15327, 15452, 15509, 15591, 15701, 15778, 15880, 15955, 16101, 16205, 16290, 16407, 16502, 16586, 16689, 16749, 16829, 16923, 16992, 17057, 17112, 17213, 17305, 17429, 17488, 17589, 17670, 17809, 17970, 18088, 18267, 18340, 18423, 18516, 18634, 18737, 18796, 18885, 18981, 19089, 19256]\n",
            "[103, 122, 62, 79, 85, 95, 61, 90, 86, 131, 122, 84, 114, 106, 69, 55, 175, 100, 85, 80, 118, 60, 128, 104, 76, 85, 59, 85, 86, 137, 78, 85, 97, 120, 110, 60, 85, 157, 91, 80, 138, 106, 83, 84, 65, 108, 98, 129, 99, 92, 111, 102, 88, 59, 72, 118, 96, 87, 90, 204, 101, 122, 75, 54, 96, 83, 78, 86, 86, 145, 97, 60, 73, 84, 124, 93, 169, 82, 107, 115, 59, 98, 114, 87, 72, 123, 100, 61, 148, 81, 113, 99, 85, 100, 76, 60, 176, 114, 103, 60, 112, 101, 97, 86, 89, 61, 162, 59, 88, 97, 121, 70, 59, 85, 97, 110, 77, 69, 139, 87, 90, 87, 67, 59, 104, 121, 107, 87, 126, 92, 61, 82, 91, 119, 97, 73, 124, 76, 67, 82, 83, 107, 122, 61, 73, 102, 167, 68, 105, 82, 95, 122, 71, 56, 88, 108, 100, 86, 109, 151, 125, 57, 82, 110, 77, 102, 75, 146, 104, 85, 117, 95, 84, 103, 60, 80, 94, 69, 65, 55, 101, 92, 124, 59, 101, 81, 139, 161, 118, 179, 73, 83, 93, 118, 103, 59, 89, 96, 108, 167]\n",
            "19256\n",
            "19256\n",
            "19256\n",
            "19256\n",
            "Running evaluation...\n",
            "602\n",
            "  0% 0/602 [00:00<?, ?it/s]x: 0\n",
            "target: 1\n",
            "  0% 0/602 [00:00<?, ?it/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/gdrive/MyDrive/emotion_recognition/2022reference/multimodal_feature_extractor_cogmen.py\", line 260, in <module>\n",
            "    for speech, text, segs, mask, label in tqdm(train_dataloader):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/tqdm/std.py\", line 1178, in __iter__\n",
            "    for obj in iterable:\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py\", line 634, in __next__\n",
            "    data = self._next_data()\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py\", line 1346, in _next_data\n",
            "    return self._process_data(data)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py\", line 1372, in _process_data\n",
            "    data.reraise()\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/_utils.py\", line 644, in reraise\n",
            "    raise exception\n",
            "TypeError: Caught TypeError in DataLoader worker process 0.\n",
            "Original Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n",
            "    data = fetcher.fetch(index)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/fetch.py\", line 54, in fetch\n",
            "    return self.collate_fn(data)\n",
            "  File \"/content/gdrive/MyDrive/emotion_recognition/2022reference/multimodal_feature_extractor_cogmen.py\", line 120, in _collate_fn\n",
            "    targets[x].narrow(0, 0, len(target)).copy_(target)\n",
            "TypeError: object of type 'int' has no len()\n",
            "\n"
          ]
        }
      ]
    }
  ]
}