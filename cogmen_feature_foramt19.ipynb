{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tip-colab-파일저장및업로드-colab",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "777c00b04207407db57b1a848552a66f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f6cb022947cd494c97082353dc04ba42",
              "IPY_MODEL_e5f62c66fdba48be8dbc4da4c00d3e4a",
              "IPY_MODEL_9680b632aaeb4d0b8c55df83683b367f"
            ],
            "layout": "IPY_MODEL_14484aed8d39497c8997aaa3daec8a15"
          }
        },
        "f6cb022947cd494c97082353dc04ba42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_89724a41f02f43008101640a0577e3fa",
            "placeholder": "​",
            "style": "IPY_MODEL_ae6335fee5e642c389432870e1c8be9a",
            "value": "  5%"
          }
        },
        "e5f62c66fdba48be8dbc4da4c00d3e4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_89a6a847ba914815949c1180b831a9bd",
            "max": 226,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b68616fd74824ca3a21b89c4ee83345e",
            "value": 12
          }
        },
        "9680b632aaeb4d0b8c55df83683b367f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a298f971ca24b95bfa38c532e19852e",
            "placeholder": "​",
            "style": "IPY_MODEL_0f16913ec5434a5f8126c2e88ac78ac3",
            "value": " 11/226 [00:08&lt;02:40,  1.34it/s]"
          }
        },
        "14484aed8d39497c8997aaa3daec8a15": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89724a41f02f43008101640a0577e3fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae6335fee5e642c389432870e1c8be9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "89a6a847ba914815949c1180b831a9bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b68616fd74824ca3a21b89c4ee83345e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9a298f971ca24b95bfa38c532e19852e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f16913ec5434a5f8126c2e88ac78ac3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/whkwls2653/Emotion-Recognition/blob/main/cogmen_feature_foramt19.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "7-JR7WQ5O70X",
        "outputId": "1c17f26e-0e36-411f-b1f3-afa7dc42c4db",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mxnet\n",
        "!pip install gluonnlp pandas tqdm\n",
        "!pip install sentencepiece\n",
        "!pip install transformers\n",
        "!pip install torc\n",
        "##Kobert pretrained model\n",
        "!pip install git+https://git@github.com/SKTBrain/KoBERT.git@master\n",
        "##numpy version for error\n",
        "!pip install numpy==1.23.1"
      ],
      "metadata": {
        "id": "AoatX7UZ8nVp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "print(np.__version__)\n",
        "import gluonnlp as nlp\n",
        "from tqdm import tqdm, tqdm_notebook"
      ],
      "metadata": {
        "id": "1jFmvtHP8nbS",
        "outputId": "eed89ff1-9beb-43c3-f73c-1fb45d6590eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.23.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#kobert\n",
        "from kobert.utils import get_tokenizer\n",
        "from kobert.pytorch_kobert import get_pytorch_kobert_model\n",
        "\n",
        "#transformers\n",
        "from transformers import AdamW\n",
        "from transformers.optimization import get_cosine_schedule_with_warmup"
      ],
      "metadata": {
        "id": "ss1Cm0Un8ne1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#GPU 사용\n",
        "device = torch.device(\"cuda:0\")\n",
        "#BERT 모델, Vocabulary 불러오기\n",
        "bertmodel, vocab = get_pytorch_kobert_model()"
      ],
      "metadata": {
        "id": "qFzol1fP8nhm",
        "outputId": "2b5175b1-94a5-489e-dfd4-e7c539dd7ae4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using cached model. /content/.cache/kobert_v1.zip\n",
            "using cached model. /content/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import pandas as pd\n",
        "import os\n",
        "import pickle\n",
        "from tqdm import tqdm\n",
        "annotation_root= '/content/gdrive/MyDrive/emotion_recognition/dataset/KEMDy19/annotation'\n",
        "txt_label_zip_toteval_root='/content/gdrive/MyDrive/emotion_recognition/dataset/2019cogmen_format.pkl'\n",
        "ambig_annotation=0\n",
        "no_file=0\n",
        "## formating features dim 9 list\n",
        "sess_ids=[]\n",
        "sess_speakers=dict()\n",
        "sess_labels=dict()\n",
        "sess_text=dict()\n",
        "sess_audio=dict()\n",
        "sess_visual=dict()\n",
        "sess_sentence=dict()\n",
        "sess_train=[]\n",
        "sess_test=[]\n",
        "if os.path.isfile(txt_label_zip_toteval_root):\n",
        "  with open(txt_label_zip_toteval_root,'rb') as f:\n",
        "    allfile_datalist=pickle.load(f)\n",
        "else:\n",
        "  allfile_datalist=[]\n",
        "  for i, annotation in tqdm(enumerate(os.listdir(annotation_root))):\n",
        "    all_txts=[]\n",
        "    # print('annotaion file : (%d / %d)'%(i,len(os.listdir(annotation_root))))\n",
        "    \n",
        "    session_file = pd.read_csv(os.path.join(annotation_root,annotation)) \n",
        "    # print(session_file) \n",
        "    segments=session_file['Segment ID']\n",
        "    session_file.loc[(session_file['Total Evaluation'] == \"fear\"), 'Total Evaluation'] = 0  #공포 => 0\n",
        "    session_file.loc[(session_file['Total Evaluation'] == \"surprise\"), 'Total Evaluation'] = 1  #놀람 => 1\n",
        "    session_file.loc[(session_file['Total Evaluation'] == \"angry\"), 'Total Evaluation'] = 2  #분노 => 2\n",
        "    session_file.loc[(session_file['Total Evaluation'] == \"sad\"), 'Total Evaluation'] = 3  #슬픔 => 3\n",
        "    session_file.loc[(session_file['Total Evaluation'] == \"neutral\"), 'Total Evaluation'] = 4  #중립 => 4\n",
        "    session_file.loc[(session_file['Total Evaluation'] == \"happy\"), 'Total Evaluation'] = 5  #행복 => 5\n",
        "    session_file.loc[(session_file['Total Evaluation'] == \"disgust\"), 'Total Evaluation'] = 6  #혐오 => 6\n",
        "\n",
        "    labels=session_file['Total Evaluation']\n",
        "\n",
        "    # print(segments)\n",
        "    ##segments == utterence  \n",
        "    for j in range(1,len(segments)):\n",
        "       #index starts from 1\n",
        "      f_name=segments[j]\n",
        "      gender=f_name.split('_')[-1][0]\n",
        "      \n",
        "      # print(\"f_name:\",f_name)\n",
        "      sess_num=f_name.split('_')[0][-2:]\n",
        "      sc_pro_num=f_name.split('_')[0]+'_'+f_name.split('_')[1]\n",
        "\n",
        "      ###texts\n",
        "      file_loc='/content/gdrive/MyDrive/emotion_recognition/dataset/KEMDy19/wav/Session%s/%s/%s.txt'%(sess_num,sc_pro_num,f_name)\n",
        "      # print(file_loc)\n",
        "      if not os.path.isfile(file_loc):\n",
        "        print(\"no file location :\",file_loc)\n",
        "        no_file+=1\n",
        "        continue\n",
        "      with open(file_loc) as f:\n",
        "        lines = f.readlines()\n",
        "      if '\\n' in lines or'/'in lines :\n",
        "        new_words=lines.replace('\\n','')\n",
        "        new_words=new_words.replace('o/','')\n",
        "        new_words=new_words.replace('I/','')\n",
        "        new_words=new_words.replace('b/','')\n",
        "        new_words=new_words.replace('u/','')\n",
        "        new_words=new_words.replace('l/','')\n",
        "        new_words=new_words.replace('n/','')\n",
        "        new_words=new_words.replace('N/','')\n",
        "        new_words=new_words.replace('s/','')\n",
        "        new_words=new_words.replace('c/','')\n",
        "        new_words=new_words.replace('(','')\n",
        "        new_words=new_words.replace(')','')\n",
        "        new_words=new_words.replace('+',' ')\n",
        "        lines=new_words\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "     \n",
        "      if sc_pro_num not in sess_ids:\n",
        "        sess_ids.append(sc_pro_num)\n",
        "        sess_speakers[sc_pro_num]=[]\n",
        "        sess_labels[sc_pro_num]=[]\n",
        "        sess_text[sc_pro_num]=[]\n",
        "        sess_audio[sc_pro_num]=[]\n",
        "        sess_visual[sc_pro_num]=[]\n",
        "        sess_sentence[sc_pro_num]=[] \n",
        "      \n",
        "      sess_speakers[sc_pro_num].append(gender)\n",
        "      sess_labels[sc_pro_num]=labels\n",
        "      sess_text[sc_pro_num].append(lines)\n",
        "      print(sess_speakers)\n",
        "      # print(sess_num,sc_pro_num)\n",
        "      \n",
        "    #  /content/gdrive/MyDrive/감정인식 대회/데이터셋/KEMDy19/wav/Session01/Sess01_script01/Sess01_script01_F001.txt\n",
        "      \n",
        "      # print(all_txts) \n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "    \n",
        "    # print(len(all_txts))\n",
        "    ## zip txts and labels,  session_file start from 1\n",
        "    if not (len(all_txts)==len(session_file['Total Evaluation'][1:])):\n",
        "      print(\"txt_session length not equal at :\",annotation,len(all_txts),len(session_file['Total Evaluation'][1:]))\n",
        "    # print(len(session_file['Total Evaluation'][1:]))\n",
        "    for q, label in zip(all_txts, session_file['Total Evaluation'][1:])  :\n",
        "      if type(label) is not int :\n",
        "        ambig_annotation+=1\n",
        "        continue\n",
        "      words=q[0]\n",
        "      if '\\n' in words or'/'in words :\n",
        "        new_words=words.replace('\\n','')\n",
        "        new_words=new_words.replace('o/','')\n",
        "        new_words=new_words.replace('I/','')\n",
        "        new_words=new_words.replace('b/','')\n",
        "        new_words=new_words.replace('u/','')\n",
        "        new_words=new_words.replace('l/','')\n",
        "        new_words=new_words.replace('n/','')\n",
        "        new_words=new_words.replace('N/','')\n",
        "        new_words=new_words.replace('s/','')\n",
        "        new_words=new_words.replace('c/','')\n",
        "        new_words=new_words.replace('(','')\n",
        "        new_words=new_words.replace(')','')\n",
        "        new_words=new_words.replace('+',' ')\n",
        "        words=new_words\n",
        "      data = []\n",
        "      data.append(words)\n",
        "      # print('Q',type(q),q[0])\n",
        "      # print('label',label)\n",
        "      data.append(str(label))\n",
        "      allfile_datalist.append(data)\n",
        "    print(allfile_datalist)\n",
        "    # allfile_datalist.append(data_list)\n",
        "\n",
        "\n",
        "\n",
        "  with open(txt_label_zip_toteval_root,'wb') as f:\n",
        "    pickle.dump(allfile_datalist,f)\n",
        "# print(\"data_list length :\",len(data_list))\n",
        "# print(\"sample : \",data_list[0])\n",
        "  \n",
        "# print(len(all_txts))\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "B48fHZNM9D1N",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        },
        "outputId": "3c351bee-ca9d-451f-ade0-ccfc71a72e9e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "0it [00:00, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-d1c3d7867d9a>\u001b[0m in \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0msc_pro_num\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msess_ids\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0msess_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc_pro_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m       \u001b[0msess_speakers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msc_pro_num\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgender\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess_speakers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m       \u001b[0;31m# print(sess_num,sc_pro_num)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Sess01_script01'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(allfile_datalist)\n",
        "print(len(allfile_datalist))"
      ],
      "metadata": {
        "id": "Dx3UkJnTju3I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a=dict()\n",
        "a['sess1']=[]\n",
        "a['sess1'].append(3)\n",
        "print(a)"
      ],
      "metadata": {
        "id": "VqIS7nLjjI6Z",
        "outputId": "cca4978c-af30-4bdb-eaeb-e3e411190e5d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'sess1': [3]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#### test1 \\n 등빼기\n",
        "if os.path.isfile(txt_label_zip_toteval_root):\n",
        "  with open(txt_label_zip_toteval_root,'rb') as f:\n",
        "    allfile_datalist_processed=pickle.load(f)\n",
        "for words in allfile_datalist_processed: \n",
        "  \n",
        "  \n",
        "  if '\\n' in words[0] or'/'in words[0] :\n",
        "    new_words=words[0].replace('\\n','')\n",
        "    new_words=new_words.replace('o/','')\n",
        "    new_words=new_words.replace('I/','')\n",
        "    new_words=new_words.replace('b/','')\n",
        "    new_words=new_words.replace('u/','')\n",
        "    new_words=new_words.replace('l/','')\n",
        "    new_words=new_words.replace('n/','')\n",
        "    new_words=new_words.replace('N/','')\n",
        "    new_words=new_words.replace('s/','')\n",
        "    new_words=new_words.replace('(','')\n",
        "    new_words=new_words.replace(')','')\n",
        "    new_words=new_words.replace('+',' ')\n",
        "    words[0]=new_words\n",
        "    # print(new_words) \n",
        "with open(txt_label_zip_toteval_root+'_processed','wb') as f:\n",
        "  pickle.dump(allfile_datalist_processed,f)"
      ],
      "metadata": {
        "id": "pXMxvqElau0f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# if os.path.isfile(txt_label_zip_toteval_root):\n",
        "with open(txt_label_zip_toteval_root+'_processed','rb') as f:\n",
        "  allfile_datalist_processed=pickle.load(f)\n",
        "  print(allfile_datalist_processed)"
      ],
      "metadata": {
        "id": "-DMdqW_iOLK2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "                                                         \n",
        "dataset_train, dataset_test = train_test_split(allfile_datalist_processed, test_size=0.25, random_state=0)\n",
        "print(len(dataset_train))\n",
        "print(len(dataset_test))"
      ],
      "metadata": {
        "id": "WNkKywK09DwZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e63f86c-b8c0-4f13-a5eb-918fb39a7150"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14442\n",
            "4815\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BERTDataset(Dataset):\n",
        "    def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer, max_len,\n",
        "                 pad, pair):\n",
        "        transform = nlp.data.BERTSentenceTransform(\n",
        "            bert_tokenizer, max_seq_length=max_len, pad=pad, pair=pair)\n",
        "\n",
        "        self.sentences = [transform([i[sent_idx]]) for i in dataset]\n",
        "        self.labels = [np.int32(i[label_idx]) for i in dataset]\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        return (self.sentences[i] + (self.labels[i], ))\n",
        "\n",
        "    def __len__(self):\n",
        "        return (len(self.labels))"
      ],
      "metadata": {
        "id": "eThFwaFt9DuG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting parameters\n",
        "max_len = 64\n",
        "batch_size = 64\n",
        "warmup_ratio = 0.1\n",
        "num_epochs = 15\n",
        "max_grad_norm = 1\n",
        "log_interval = 200\n",
        "learning_rate =  5e-5"
      ],
      "metadata": {
        "id": "eppLk7OO9Dq6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = get_tokenizer()\n",
        "tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)\n",
        "\n",
        "data_train = BERTDataset(dataset_train, 0, 1, tok, max_len, True, False)\n",
        "data_test = BERTDataset(dataset_test, 0, 1, tok, max_len, True, False)"
      ],
      "metadata": {
        "id": "JL6UYUwa9DlR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6041ee47-317a-4c40-d5f7-56ab3a644477"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using cached model. /content/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = torch.utils.data.DataLoader(data_train, batch_size=batch_size, num_workers=5)\n",
        "test_dataloader = torch.utils.data.DataLoader(data_test, batch_size=batch_size, num_workers=5)"
      ],
      "metadata": {
        "id": "Fi7maNb78nkd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1f15275-fbe6-475a-e172-7b3c4987dc88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BERTClassifier(nn.Module):\n",
        "    def __init__(self,\n",
        "                 bert,\n",
        "                 hidden_size = 768,\n",
        "                 num_classes=7,   ##클래스 수 조정##\n",
        "                 dr_rate=None,\n",
        "                 params=None):\n",
        "        super(BERTClassifier, self).__init__()\n",
        "        self.bert = bert\n",
        "        self.dr_rate = dr_rate\n",
        "                 \n",
        "        self.classifier = nn.Linear(hidden_size , num_classes)\n",
        "        if dr_rate:\n",
        "            self.dropout = nn.Dropout(p=dr_rate)\n",
        "    \n",
        "    def gen_attention_mask(self, token_ids, valid_length):\n",
        "        attention_mask = torch.zeros_like(token_ids)\n",
        "        for i, v in enumerate(valid_length):\n",
        "            attention_mask[i][:v] = 1\n",
        "        return attention_mask.float()\n",
        "\n",
        "    def forward(self, token_ids, valid_length, segment_ids):\n",
        "        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n",
        "        \n",
        "        _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device))\n",
        "        if self.dr_rate:\n",
        "            out = self.dropout(pooler)\n",
        "        return self.classifier(out)\n",
        "#BERT 모델 불러오기\n",
        "model = BERTClassifier(bertmodel,  dr_rate=0.5)#.to(device)\n",
        "\n",
        "#optimizer와 schedule 설정\n",
        "no_decay = ['bias', 'LayerNorm.weight']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
        "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "]\n",
        "\n",
        "optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "t_total = len(train_dataloader) * num_epochs\n",
        "warmup_step = int(t_total * warmup_ratio)\n",
        "\n",
        "scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=warmup_step, num_training_steps=t_total)\n",
        "\n",
        "#정확도 측정을 위한 함수 정의\n",
        "def calc_accuracy(X,Y):\n",
        "    max_vals, max_indices = torch.max(X, 1)\n",
        "    train_acc = (max_indices == Y).sum().data.cpu().numpy()/max_indices.size()[0]\n",
        "    return train_acc\n",
        "    \n",
        "train_dataloader"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fMXyRO5ha-uy",
        "outputId": "8c27b0c7-aecc-49ba-a41d-02c1a03a221e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.utils.data.dataloader.DataLoader at 0x7fa8e9ad6070>"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##train\n",
        "for e in range(num_epochs):\n",
        "    train_acc = 0.0\n",
        "    test_acc = 0.0\n",
        "    model.train().to(device)\n",
        "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(train_dataloader)):\n",
        "        optimizer.zero_grad()\n",
        "        token_ids = token_ids.long().to(device)\n",
        "        segment_ids = segment_ids.long().to(device)\n",
        "        valid_length= valid_length\n",
        "        label = label.long().to(device)\n",
        "        out = model(token_ids, valid_length, segment_ids)\n",
        "        loss = loss_fn(out, label)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
        "        optimizer.step()\n",
        "        scheduler.step()  # Update learning rate schedule\n",
        "        train_acc += calc_accuracy(out, label)\n",
        "        if batch_id % log_interval == 0:\n",
        "            print(\"epoch {} batch id {} loss {} train acc {}\".format(e+1, batch_id+1, loss.data.cpu().numpy(), train_acc / (batch_id+1)))\n",
        "    print(\"epoch {} train acc {}\".format(e+1, train_acc / (batch_id+1)))\n",
        "    \n",
        "    model.eval()\n",
        "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(test_dataloader)):\n",
        "        token_ids = token_ids.long().to(device)\n",
        "        segment_ids = segment_ids.long().to(device)\n",
        "        valid_length= valid_length\n",
        "        label = label.long().to(device)\n",
        "        out = model(token_ids, valid_length, segment_ids)\n",
        "        test_acc += calc_accuracy(out, label)\n",
        "    print(\"epoch {} test acc {}\".format(e+1, test_acc / (batch_id+1)))\n",
        "\n",
        "torch.save({\n",
        "            'epoch': num_epochs,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': loss,\n",
        "            }, '/content/gdrive/MyDrive/감정인식 대회/데이터셋/2019_processed_15epoch')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179,
          "referenced_widgets": [
            "777c00b04207407db57b1a848552a66f",
            "f6cb022947cd494c97082353dc04ba42",
            "e5f62c66fdba48be8dbc4da4c00d3e4a",
            "9680b632aaeb4d0b8c55df83683b367f",
            "14484aed8d39497c8997aaa3daec8a15",
            "89724a41f02f43008101640a0577e3fa",
            "ae6335fee5e642c389432870e1c8be9a",
            "89a6a847ba914815949c1180b831a9bd",
            "b68616fd74824ca3a21b89c4ee83345e",
            "9a298f971ca24b95bfa38c532e19852e",
            "0f16913ec5434a5f8126c2e88ac78ac3"
          ]
        },
        "id": "UKTiibQVa-sj",
        "outputId": "b94b7e5d-9d87-4b04-a8b8-de71da339f2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-101-752f5961bdb8>:6: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(train_dataloader)):\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/226 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "777c00b04207407db57b1a848552a66f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1 batch id 1 loss 0.7593756914138794 train acc 0.671875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = get_tokenizer()\n",
        "tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)\n",
        "\n",
        "def predict(predict_sentence):\n",
        "\n",
        "    data = [predict_sentence, '0']\n",
        "    dataset_another = [data]\n",
        "\n",
        "    another_test = BERTDataset(dataset_another, 0, 1, tok, max_len, True, False)\n",
        "    test_dataloader = torch.utils.data.DataLoader(another_test, batch_size=batch_size, num_workers=5)\n",
        "    \n",
        "    model.eval()\n",
        "\n",
        "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(test_dataloader):\n",
        "        token_ids = token_ids.long().to(device)\n",
        "        segment_ids = segment_ids.long().to(device)\n",
        "\n",
        "        valid_length= valid_length\n",
        "        label = label.long().to(device)\n",
        "\n",
        "        out = model(token_ids, valid_length, segment_ids)\n",
        "\n",
        "\n",
        "        test_eval=[]\n",
        "        for i in out:\n",
        "            logits=i\n",
        "            logits = logits.detach().cpu().numpy()\n",
        "\n",
        "            if np.argmax(logits) == 0:\n",
        "                test_eval.append(\"공포가\")\n",
        "            elif np.argmax(logits) == 1:\n",
        "                test_eval.append(\"놀람이\")\n",
        "            elif np.argmax(logits) == 2:\n",
        "                test_eval.append(\"분노가\")\n",
        "            elif np.argmax(logits) == 3:\n",
        "                test_eval.append(\"슬픔이\")\n",
        "            elif np.argmax(logits) == 4:\n",
        "                test_eval.append(\"중립이\")\n",
        "            elif np.argmax(logits) == 5:\n",
        "                test_eval.append(\"행복이\")\n",
        "            elif np.argmax(logits) == 6:\n",
        "                test_eval.append(\"혐오가\")\n",
        "\n",
        "        print(\">> 입력하신 내용에서 \" + test_eval[0] + \" 느껴집니다.\")\n",
        "end = 1\n",
        "while end == 1 :\n",
        "    sentence = input(\"하고싶은 말을 입력해주세요 : \")\n",
        "    if sentence == 0 :\n",
        "        break\n",
        "    predict(sentence)\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "id": "858CpYNXa-qg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2975d131-5154-4daf-c09f-82d81b2af46d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using cached model. /content/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n",
            "하고싶은 말을 입력해주세요 : 라면좋아\n",
            ">> 입력하신 내용에서 중립이 느껴집니다.\n",
            "\n",
            "\n",
            "하고싶은 말을 입력해주세요 : 라면 먹으니 행복해\n",
            ">> 입력하신 내용에서 중립이 느껴집니다.\n",
            "\n",
            "\n",
            "하고싶은 말을 입력해주세요 : 화가나네\n",
            ">> 입력하신 내용에서 분노가 느껴집니다.\n",
            "\n",
            "\n",
            "하고싶은 말을 입력해주세요 : 역겨워\n",
            ">> 입력하신 내용에서 중립이 느껴집니다.\n",
            "\n",
            "\n",
            "하고싶은 말을 입력해주세요 : 어두운게 무서워\n",
            ">> 입력하신 내용에서 공포가 느껴집니다.\n",
            "\n",
            "\n",
            "하고싶은 말을 입력해주세요 : 어제 헤어졌어\n",
            ">> 입력하신 내용에서 슬픔이 느껴집니다.\n",
            "\n",
            "\n",
            "하고싶은 말을 입력해주세요 : 주식이 많이 올랐어\n",
            ">> 입력하신 내용에서 중립이 느껴집니다.\n",
            "\n",
            "\n",
            "하고싶은 말을 입력해주세요 : 날씨가 너무 맑다!\n",
            ">> 입력하신 내용에서 중립이 느껴집니다.\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-100-202bd4929d63>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"하고싶은 말을 입력해주세요 : \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m             )\n\u001b[0;32m--> 860\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    861\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    902\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 904\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    905\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fGSFs-Z6a-oL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g0f6Zou4a-mE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "h3BLdqy7a-j-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7BBac7CPa-gq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LuspU6xca-Ym"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}