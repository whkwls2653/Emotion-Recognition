{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tip-colab-파일저장및업로드-colab",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/whkwls2653/Emotion-Recognition/blob/main/total.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "7-JR7WQ5O70X",
        "outputId": "442f6609-c94f-4256-8842-339638260c7a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#2022refernce\n",
        "!pip install transformers\n",
        "!pip install sklearn\n",
        "!pip install scipy\n",
        "!pip install pandas\n",
        "!pip install audtorch\n",
        "\n",
        "##cogmen\n",
        "!pip install torch_geometric\n",
        "!pip install comet-ml\n",
        "!pip install -U sentence-transformers"
      ],
      "metadata": {
        "id": "D6OwESwzQd96"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fGSFs-Z6a-oL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oqpfxgp-U4mC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# cogmen codes"
      ],
      "metadata": {
        "id": "axfsVILt7m2P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/gdrive/MyDrive/emotion_recognition/COGMEN_code/\n",
        "!python preprocess.py --dataset=\"KEMDy19\"\n",
        "\n",
        "%cd /content/gdrive/MyDrive/emotion_recognition/COGMEN_code/\n",
        "!python train.py --dataset=\"KEMDy19\" --modalities=\"t\" --from_begin --epochs=55\n",
        "\n",
        "!    python eval.py --dataset=\"iemocap_4\" --modalities=\"atv\""
      ],
      "metadata": {
        "id": "xTmo4iYswJXn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "foAyPj4jbjAs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "L3DOAXQ77oxk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2022 reference codes"
      ],
      "metadata": {
        "id": "33qV0xCJ7pXP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/gdrive/MyDrive/emotion_recognition/2022reference\n",
        "!python multimodal_classification_concat.py --batch_size 16 --lr 1e-5 --num_fold 1 --dataset 19 --dataset_dir '/content/gdrive/MyDrive/emotion_recognition/dataset/KEMDy19'\n",
        "%cd /content/gdrive/MyDrive/emotion_recognition/2022reference\n",
        "!python multimodal_feature_extractor_cogmen.py --batch_size 16 --lr 1e-5 --num_fold 1 --dataset 19 --dataset_dir '/content/gdrive/MyDrive/emotion_recognition/dataset/KEMDy19'"
      ],
      "metadata": {
        "id": "O7JgXI1yN0Gr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle as pkl\n",
        "# import os\n",
        "# # make_label=[]\n",
        "# makelabel_root='/content/gdrive/MyDrive/emotion_recognition/2022reference/KEMDy19/all_arousal_19.pkl'\n",
        "txt_feats_root='/content/gdrive/MyDrive/emotion_recognition/2022reference/KEMDy19/txt_feats_1.pkl'\n",
        "# print(os.path.isfile(makelabel_root))\n",
        "with open(txt_feats_root,'rb') as f:\n",
        "  txt_feats=pkl.load(f)\n",
        "wav_feats_root='/content/gdrive/MyDrive/emotion_recognition/2022reference/KEMDy19/wav_feats_1.pkl'\n",
        "# print(os.path.isfile(makelabel_root))\n",
        "with open(wav_feats_root,'rb') as f:\n",
        "  wav_feats=pkl.load(f)\n",
        "\n",
        "\n",
        "# print(len(make_label))\n",
        "print(txt_feats[0][0].shape)\n",
        "print(wav_feats[0][0].shape)\n",
        "\n",
        "print(type(txt_feats[0][0]))\n",
        "print(type(wav_feats[0][0]))\n",
        "\n",
        "print(txt_feats[0][0].dtype)\n",
        "print(wav_feats[0][0].dtype)\n"
      ],
      "metadata": {
        "id": "g0f6Zou4a-mE",
        "outputId": "ab8cc616-43ae-48ec-97cf-6e38d38bb052",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([768])\n",
            "torch.Size([512])\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "torch.float32\n",
            "torch.float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/gdrive/MyDrive/emotion_recognition/2022reference\n",
        "!python multimodal_feature_extractor.py --batch_size 16 --lr 1e-5 --dataset 19 --dataset_dir '/content/gdrive/MyDrive/emotion_recognition/dataset/KEMDy19'"
      ],
      "metadata": {
        "id": "h3BLdqy7a-j-",
        "outputId": "f9db4910-8a48-45a9-a917-1101254aae1d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/emotion_recognition/2022reference\n",
            "/content/gdrive/MyDrive/emotion_recognition/2022reference/multimodal_feature_extractor.py:153: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "  usecols_element = [3, 4, 5, 6] if args.dataset is 20 else [9, 10, 11, 12]\n",
            "2023-04-03 09:42:27.969116: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "device: cuda\n",
            "1\n",
            "2\n",
            "load from 19\n",
            "Some weights of the model checkpoint at facebook/wav2vec2-base-960h were not used when initializing Wav2Vec2Model: ['lm_head.weight', 'lm_head.bias']\n",
            "- This IS expected if you are initializing Wav2Vec2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing Wav2Vec2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Running evaluation...\n",
            "1285\n",
            "100% 1285/1285 [13:38<00:00,  1.57it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle as pkl\n",
        "txt_feats1_root='/content/gdrive/MyDrive/emotion_recognition/2022reference/KEMDy19/wav_feats_1.pkl'\n",
        "# print(os.path.isfile(makelabel_root))\n",
        "with open(txt_feats1_root,'rb') as f:\n",
        "  txt_feats1=pkl.load(f)\n",
        "txt_feats2_root='/content/gdrive/MyDrive/emotion_recognition/2022reference/KEMDy19/wav_feats_2.pkl'\n",
        "# print(os.path.isfile(makelabel_root))\n",
        "with open(txt_feats2_root,'rb') as f:\n",
        "  txt_feats2=pkl.load(f)\n",
        "\n",
        "all_txt_feats=[]\n",
        "for batch in txt_feats1:\n",
        "  for data in batch:\n",
        "    all_txt_feats.append(data)\n",
        "for batch in txt_feats2:\n",
        "  for data in batch:\n",
        "    all_txt_feats.append(data)\n",
        "\n"
      ],
      "metadata": {
        "id": "cV9qojtIcirB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(all_txt_feats[1])\n",
        "all_txt_feats_root='/content/gdrive/MyDrive/emotion_recognition/2022reference/KEMDy19/all_wav_feats.pkl'\n",
        "with open(all_txt_feats_root,'wb') as f:\n",
        "  pkl.dump(all_txt_feats,f)"
      ],
      "metadata": {
        "id": "7BBac7CPa-gq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# txt_feats1_root='/content/gdrive/MyDrive/emotion_recognition/2022reference/KEMDy19/all_txt_feats.pkl'\n",
        "# # print(os.path.isfile(makelabel_root))\n",
        "# with open(txt_feats1_root,'rb') as f:\n",
        "#   txt_feats=pkl.load(f)\n",
        "print(txt_feats[0])"
      ],
      "metadata": {
        "id": "LuspU6xca-Ym"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}