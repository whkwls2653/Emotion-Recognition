{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tip-colab-ÌååÏùºÏ†ÄÏû•Î∞èÏóÖÎ°úÎìú-colab",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "249df727c9fa4d5a962eb765be84483f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5a534e02f5974c2fb44905dc84fb8709",
              "IPY_MODEL_8a7c3d1e43ac4fdaa3718cf74e4888e8",
              "IPY_MODEL_727b00dc1d4d4b2e86b0e1ef9c2070a4"
            ],
            "layout": "IPY_MODEL_4474bf7bbdcc446897e5a238b730d0ec"
          }
        },
        "5a534e02f5974c2fb44905dc84fb8709": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_19d3bf359c5544d79bd4724f3b9a0fc5",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_059bb09bec60441b908de2cba81c6f1a",
            "value": "Downloading builder script: "
          }
        },
        "8a7c3d1e43ac4fdaa3718cf74e4888e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3468b15888164b01a7898934c7bc7ef4",
            "max": 1901,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_12dee88b0ee44ed983dfcb21b205b37c",
            "value": 1901
          }
        },
        "727b00dc1d4d4b2e86b0e1ef9c2070a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1855e1af9a844c0fb5a541533c0dd1a2",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_c6f9222abf274fb9ad74f0670009cf65",
            "value": " 4.48k/? [00:00&lt;00:00, 223kB/s]"
          }
        },
        "4474bf7bbdcc446897e5a238b730d0ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19d3bf359c5544d79bd4724f3b9a0fc5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "059bb09bec60441b908de2cba81c6f1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3468b15888164b01a7898934c7bc7ef4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12dee88b0ee44ed983dfcb21b205b37c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1855e1af9a844c0fb5a541533c0dd1a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6f9222abf274fb9ad74f0670009cf65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/whkwls2653/Emotion-Recognition/blob/main/wav2vec_local.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "7-JR7WQ5O70X",
        "outputId": "b5c0ef1c-4c44-427b-96ea-0445a91feb99",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "                                                         \n",
        "dataset_train, dataset_test = train_test_split(allfile_datalist, test_size=0.25, random_state=0)\n",
        "print(len(dataset_train))\n",
        "print(len(dataset_test))"
      ],
      "metadata": {
        "id": "WNkKywK09DwZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers==4.11.3\n",
        "!pip install torchaudio\n",
        "!pip install librosa\n",
        "!pip install jiwer\n",
        "!pip install dataset"
      ],
      "metadata": {
        "id": "858CpYNXa-qg",
        "outputId": "9b14764b-710d-4079-b8f5-20162dd934c6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers==4.11.3\n",
            "  Downloading transformers-4.11.3-py3-none-any.whl (2.9 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m78.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers==4.11.3) (3.10.7)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers==4.11.3) (6.0)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m880.6/880.6 KB\u001b[0m \u001b[31m69.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers==4.11.3) (2.27.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers==4.11.3) (23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers==4.11.3) (2022.10.31)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m105.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers==4.11.3) (4.65.0)\n",
            "Collecting huggingface-hub>=0.0.17\n",
            "  Downloading huggingface_hub-0.13.3-py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m199.8/199.8 KB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers==4.11.3) (1.22.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.0.17->transformers==4.11.3) (4.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers==4.11.3) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers==4.11.3) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers==4.11.3) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers==4.11.3) (2.0.12)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from sacremoses->transformers==4.11.3) (1.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from sacremoses->transformers==4.11.3) (8.1.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from sacremoses->transformers==4.11.3) (1.1.1)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895259 sha256=575c7ae6615dec7e7509669c780f0d3700944a9892904ba0c948b1f8dae6cb00\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/1c/3d/46cf06718d63a32ff798a89594b61e7f345ab6b36d909ce033\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.13.3 sacremoses-0.0.53 tokenizers-0.10.3 transformers-4.11.3\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.9/dist-packages (0.13.1+cu116)\n",
            "Requirement already satisfied: torch==1.13.1 in /usr/local/lib/python3.9/dist-packages (from torchaudio) (1.13.1+cu116)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch==1.13.1->torchaudio) (4.5.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.9/dist-packages (0.10.0.post2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.9/dist-packages (from librosa) (0.56.4)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.9/dist-packages (from librosa) (0.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.9/dist-packages (from librosa) (1.1.1)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.9/dist-packages (from librosa) (1.10.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.9/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.9/dist-packages (from librosa) (1.0.5)\n",
            "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in /usr/local/lib/python3.9/dist-packages (from librosa) (1.22.4)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.9/dist-packages (from librosa) (1.2.2)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.9/dist-packages (from librosa) (4.5.0)\n",
            "Requirement already satisfied: pooch<1.7,>=1.0 in /usr/local/lib/python3.9/dist-packages (from librosa) (1.6.0)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.9/dist-packages (from librosa) (0.3.4)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.9/dist-packages (from librosa) (3.0.0)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.9/dist-packages (from librosa) (0.12.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from numba>=0.51.0->librosa) (67.6.1)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.9/dist-packages (from numba>=0.51.0->librosa) (0.39.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.9/dist-packages (from pooch<1.7,>=1.0->librosa) (2.27.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from pooch<1.7,>=1.0->librosa) (23.0)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.9/dist-packages (from pooch<1.7,>=1.0->librosa) (1.4.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.20.0->librosa) (3.1.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.9/dist-packages (from soundfile>=0.12.1->librosa) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.9/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.21)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->pooch<1.7,>=1.0->librosa) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->pooch<1.7,>=1.0->librosa) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->pooch<1.7,>=1.0->librosa) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->pooch<1.7,>=1.0->librosa) (2.0.12)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting jiwer\n",
            "  Downloading jiwer-3.0.1-py3-none-any.whl (21 kB)\n",
            "Collecting rapidfuzz==2.13.7\n",
            "  Downloading rapidfuzz-2.13.7-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m57.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click<9.0.0,>=8.1.3 in /usr/local/lib/python3.9/dist-packages (from jiwer) (8.1.3)\n",
            "Installing collected packages: rapidfuzz, jiwer\n",
            "Successfully installed jiwer-3.0.1 rapidfuzz-2.13.7\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting dataset\n",
            "  Downloading dataset-1.6.0-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: sqlalchemy<2.0.0,>=1.3.2 in /usr/local/lib/python3.9/dist-packages (from dataset) (1.4.47)\n",
            "Collecting banal>=1.0.1\n",
            "  Downloading banal-1.0.6-py2.py3-none-any.whl (6.1 kB)\n",
            "Collecting alembic>=0.6.2\n",
            "  Downloading alembic-1.10.2-py3-none-any.whl (212 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m212.2/212.2 KB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.9/dist-packages (from alembic>=0.6.2->dataset) (4.5.0)\n",
            "Collecting Mako\n",
            "  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m78.7/78.7 KB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.9/dist-packages (from sqlalchemy<2.0.0,>=1.3.2->dataset) (2.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.9/dist-packages (from Mako->alembic>=0.6.2->dataset) (2.1.2)\n",
            "Installing collected packages: banal, Mako, alembic, dataset\n",
            "Successfully installed Mako-1.2.4 alembic-1.10.2 banal-1.0.6 dataset-1.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from dataclasses import dataclass, field\n",
        "from typing import Any, Dict, List, Optional, Union\n",
        "\n",
        "import torch\n",
        "import ast\n",
        "from transformers import Wav2Vec2Processor\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "@dataclass\n",
        "class DataCollatorCTCWithPadding:\n",
        "    processor: Wav2Vec2Processor.from_pretrained(\"/content/gdrive/MyDrive/·ÑÄ·Ö°·Ü∑·Ñå·Ö•·Üº·Ñã·Öµ·Ü´·Ñâ·Öµ·Ü®_·ÑÉ·Ö¢·Ñí·Ö¨/wave2vec2\", pad_token_id=49)\n",
        "    padding: Union[bool, str] = True\n",
        "    max_length: Optional[int] = None\n",
        "    max_length_labels: Optional[int] = None\n",
        "    pad_to_multiple_of: Optional[int] = None\n",
        "    pad_to_multiple_of_labels: Optional[int] = None\n",
        "\n",
        "    def mapping(self,data):\n",
        "        with self.processor.as_target_processor():\n",
        "            ret = self.processor(\"\".join([i if i!='\\x1b' else '|' for i in ast.literal_eval(data)])).input_ids\n",
        "            ret_torch = torch.tensor([int(0 if value is None else value) for value in ret])\n",
        "        return ret_torch\n",
        "\n",
        "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
        "        # split inputs and labels since they have to be of different lenghts and need\n",
        "        # different padding methods\n",
        "        input_features = [{\"input_values\": feature['input_values']} for feature in features]\n",
        "        # e.g. feature['label'] = \"„Öá„Öè„Ñ¥„Ñ¥„Öï„Öá„Öé„Öè„ÖÖ„Öî„Öá„Öõ\"\n",
        "        label_features = [{\"input_ids\": self.mapping(feature[\"label\"])} for feature in features]\n",
        "\n",
        "        batch = self.processor.pad(\n",
        "            input_features,\n",
        "            padding=self.padding,\n",
        "            max_length=self.max_length,\n",
        "            pad_to_multiple_of=self.pad_to_multiple_of,\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "        with self.processor.as_target_processor():\n",
        "            labels_batch = self.processor.pad(\n",
        "                label_features,\n",
        "                padding=self.padding,\n",
        "                max_length=self.max_length_labels,\n",
        "                pad_to_multiple_of=self.pad_to_multiple_of_labels,\n",
        "                return_tensors=\"pt\",\n",
        "            )\n",
        "\n",
        "        # replace padding with -100 to ignore loss correctly\n",
        "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
        "        batch[\"labels\"] = labels\n",
        "\n",
        "        return batch\n",
        "\n",
        "\n",
        "# ÏûêÏÜå Îã®ÏúÑÎ°ú ÎÇòÎàÑÏñ¥ÏßÄÏßÄ ÏïäÏùÄ Í≤ΩÏö∞ ÏÇ¨Ïö© -> ÌïúÎ≤à ÌïòÎ©¥ Ï†ÄÏû•Ìï¥ÎÜìÍ∏∞\n",
        "class DataProc:\n",
        "    def __init__(self, model_name=\"/content/gdrive/MyDrive/·ÑÄ·Ö°·Ü∑·Ñå·Ö•·Üº·Ñã·Öµ·Ü´·Ñâ·Öµ·Ü®_·ÑÉ·Ö¢·Ñí·Ö¨/wave2vec2\"):\n",
        "        self.processor = Wav2Vec2Processor.from_pretrained(model_name, pad_token_id=49)\n",
        "\n",
        "    def to_jaso(self, sentence):\n",
        "        NO_JONGSUNG = ''\n",
        "        CHOSUNGS = ['„Ñ±', '„Ñ≤', '„Ñ¥', '„Ñ∑', '„Ñ∏', '„Ñπ', '„ÖÅ', '„ÖÇ', '„ÖÉ', '„ÖÖ', '„ÖÜ', '„Öá', '„Öà', '„Öâ', '„Öä', '„Öã', '„Öå', '„Öç', '„Öé']\n",
        "        JOONGSUNGS = ['„Öè', '„Öê', '„Öë', '„Öí', '„Öì', '„Öî', '„Öï', '„Öñ', '„Öó', '„Öò', '„Öô', '„Öö', '„Öõ', '„Öú', '„Öù', '„Öû', '„Öü', '„Ö†', '„Ö°', '„Ö¢', '„Ö£']\n",
        "        JONGSUNGS = [NO_JONGSUNG,  '„Ñ±', '„Ñ≤', '„Ñ≥', '„Ñ¥', '„Ñµ', '„Ñ∂', '„Ñ∑', '„Ñπ', '„Ñ∫', '„Ñª', '„Ñº', '„ÑΩ', '„Ñæ', '„Ñø', '„ÖÄ', '„ÖÅ', '„ÖÇ', '„ÖÑ', '„ÖÖ', '„ÖÜ', '„Öá', '„Öà', '„Öä', '„Öã', '„Öå', '„Öç', '„Öé']\n",
        "\n",
        "        N_CHOSUNGS, N_JOONGSUNGS, N_JONGSUNGS = 19, 21, 28\n",
        "        FIRST_HANGUL, LAST_HANGUL = 0xAC00, 0xD7A3 #'Í∞Ä', 'Ìû£'    \n",
        "     \n",
        "        result = []\n",
        "        for char in sentence:\n",
        "            if ord(char) < FIRST_HANGUL or ord(char) > LAST_HANGUL: \n",
        "                result.append('|')\n",
        "            else:          \n",
        "                code = ord(char) - FIRST_HANGUL\n",
        "                jongsung_index = code % N_JONGSUNGS\n",
        "                code //= N_JONGSUNGS\n",
        "                joongsung_index = code % N_JOONGSUNGS\n",
        "                code //= N_JOONGSUNGS\n",
        "                chosung_index = code\n",
        "                result.append(CHOSUNGS[chosung_index])\n",
        "                result.append(JOONGSUNGS[joongsung_index])\n",
        "                if jongsung_index!=0:\n",
        "                    result.append(JONGSUNGS[jongsung_index])\n",
        "                \n",
        "        with self.processor.as_target_processor():\n",
        "            ret = self.processor(\"\".join(result))\n",
        "        \n",
        "        return ret.input_ids\n",
        "\n",
        "    def prepare_dataset(self, df):\n",
        "        \"\"\"\n",
        "        df.cols = ['audio', 'sentence', 'path']\n",
        "        \"\"\"\n",
        "        df['label'] = df['sentence'].apply(self.to_jaso)\n",
        "        return df"
      ],
      "metadata": {
        "id": "fGSFs-Z6a-oL"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets\n",
        "# import datasets\n",
        "from datasets import load_metric, load_from_disk\n",
        "# from data_proc import  get_senior_data\n",
        "# from data_collator import DataCollatorCTCWithPadding\n",
        "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor\n",
        "from transformers import TrainingArguments, Trainer\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "import ast\n",
        "\n",
        "import numpy as np\n",
        "# import os\n",
        "# os.environ['CUDA_LAUNCH_BLOCKING']='1'\n",
        "# os.environ['CUDA_VISIBLE_DEVICES'] = \"2,3\"\n",
        "\n",
        "repo_name = '/content/gdrive/MyDrive/·ÑÄ·Ö°·Ü∑·Ñå·Ö•·Üº·Ñã·Öµ·Ü´·Ñâ·Öµ·Ü®_·ÑÉ·Ö¢·Ñí·Ö¨/wave2vec2'\n",
        "\n",
        "processor = Wav2Vec2Processor.from_pretrained('/content/gdrive/MyDrive/·ÑÄ·Ö°·Ü∑·Ñå·Ö•·Üº·Ñã·Öµ·Ü´·Ñâ·Öµ·Ü®_·ÑÉ·Ö¢·Ñí·Ö¨/wave2vec2')\n",
        "wer_metric = load_metric(\"wer\")\n",
        "data_collator = DataCollatorCTCWithPadding(processor=processor, padding=True)\n",
        "\n",
        "def compute_metrics(pred):\n",
        "    pred_logits = pred.predictions\n",
        "    pred_ids = np.argmax(pred_logits, axis=-1)\n",
        "    pred.label_ids[pred.label_ids == -100] = 49 # as fleek model has 2 pad tokens\n",
        "    pred_str = processor.batch_decode(pred_ids)\n",
        "    label_str = processor.batch_decode(pred.label_ids, group_tokens=False)\n",
        "\n",
        "    wer = wer_metric.compute(predictions=pred_str, references=label_str)\n",
        "\n",
        "    return {\"wer\": wer}\n",
        "\n",
        "def get_model(model_name=\"/content/gdrive/MyDrive/·ÑÄ·Ö°·Ü∑·Ñå·Ö•·Üº·Ñã·Öµ·Ü´·Ñâ·Öµ·Ü®_·ÑÉ·Ö¢·Ñí·Ö¨/wave2vec2\"): \n",
        "    model = Wav2Vec2ForCTC.from_pretrained(\n",
        "        model_name, \n",
        "        attention_dropout=0.1,\n",
        "        hidden_dropout=0.1,\n",
        "        feat_proj_dropout=0.0,\n",
        "        mask_time_prob=0.05,\n",
        "        layerdrop=0.1,\n",
        "        ctc_loss_reduction=\"mean\", \n",
        "        pad_token_id=49,\n",
        "        vocab_size=50,\n",
        "        ignore_mismatched_sizes=True\n",
        "    )\n",
        "\n",
        "    model.freeze_feature_extractor()\n",
        "    model.gradient_checkpointing_enable()\n",
        "    return model\n",
        "\n",
        "def train_model(train, test, model):\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=repo_name,\n",
        "        group_by_length=True,\n",
        "        per_device_train_batch_size=32,\n",
        "        per_device_eval_batch_size=32,\n",
        "        gradient_accumulation_steps=4,\n",
        "        evaluation_strategy=\"steps\",\n",
        "        num_train_epochs=30,\n",
        "        fp16=True,\n",
        "        save_steps=300,\n",
        "        eval_steps=300,\n",
        "        logging_steps=50,\n",
        "        learning_rate=3e-4,\n",
        "        warmup_steps=300,\n",
        "        save_total_limit=1,\n",
        "        load_best_model_at_end=True,\n",
        "        metric_for_best_model='eval_loss',\n",
        "        dataloader_num_workers=6\n",
        "        )\n",
        "\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        compute_metrics=compute_metrics,\n",
        "        train_dataset=train,\n",
        "        eval_dataset=test,\n",
        "        tokenizer=processor.feature_extractor,\n",
        "        data_collator=data_collator\n",
        "    )\n",
        "    print(f\"build trainer on device {training_args.device} with {training_args.n_gpu} gpus\")\n",
        "    trainer.train()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    \n",
        "    # torch.cuda.empty_cache()\n",
        "    \n",
        "    # dataset = load_from_disk('./elders_dataset')\n",
        "    # dataset = dataset.remove_columns(['wav', 'text', 'labels'])\n",
        "\n",
        "    # train = dataset['train'] #.select([i for i in range(0,5000)])\n",
        "    # test =  dataset['valid'] #.select([i for i in range(0,5000)])\n",
        "\n",
        "    model = get_model()\n",
        "    train_model(train, test, model)"
      ],
      "metadata": {
        "id": "g0f6Zou4a-mE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "249df727c9fa4d5a962eb765be84483f",
            "5a534e02f5974c2fb44905dc84fb8709",
            "8a7c3d1e43ac4fdaa3718cf74e4888e8",
            "727b00dc1d4d4b2e86b0e1ef9c2070a4",
            "4474bf7bbdcc446897e5a238b730d0ec",
            "19d3bf359c5544d79bd4724f3b9a0fc5",
            "059bb09bec60441b908de2cba81c6f1a",
            "3468b15888164b01a7898934c7bc7ef4",
            "12dee88b0ee44ed983dfcb21b205b37c",
            "1855e1af9a844c0fb5a541533c0dd1a2",
            "c6f9222abf274fb9ad74f0670009cf65"
          ]
        },
        "outputId": "fd133a89-ad1d-4d09-f5c0-eabbce54f538"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.11.0-py3-none-any.whl (468 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m468.7/468.7 KB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from datasets) (1.4.4)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-3.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m212.2/212.2 KB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (0.13.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.9/dist-packages (from datasets) (4.65.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from datasets) (23.0)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.9/dist-packages (from datasets) (2023.3.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from datasets) (1.22.4)\n",
            "Collecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Collecting multiprocess\n",
            "  Downloading multiprocess-0.70.14-py39-none-any.whl (132 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m132.9/132.9 KB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiohttp\n",
            "  Downloading aiohttp-3.8.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m76.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from datasets) (6.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (2.27.1)\n",
            "Collecting dill<0.3.7,>=0.3.0\n",
            "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m110.5/110.5 KB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m114.2/114.2 KB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m158.8/158.8 KB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.8.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (264 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m264.6/264.6 KB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (2.0.12)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (22.2.0)\n",
            "Collecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Collecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (3.10.7)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.5.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: xxhash, multidict, frozenlist, dill, async-timeout, yarl, responses, multiprocess, aiosignal, aiohttp, datasets\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 datasets-2.11.0 dill-0.3.6 frozenlist-1.3.3 multidict-6.0.4 multiprocess-0.70.14 responses-0.18.0 xxhash-3.2.0 yarl-1.8.2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-035576590896>:20: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ü§ó Evaluate: https://huggingface.co/docs/evaluate\n",
            "  wer_metric = load_metric(\"wer\")\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/1.90k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "249df727c9fa4d5a962eb765be84483f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-035576590896>\u001b[0m in \u001b[0;36m<cell line: 85>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m     \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "annotation_root= '/content/gdrive/MyDrive/·ÑÄ·Ö°·Ü∑·Ñå·Ö•·Üº·Ñã·Öµ·Ü´·Ñâ·Öµ·Ü® ·ÑÉ·Ö¢·Ñí·Ö¨/·ÑÉ·Ö¶·Ñã·Öµ·Ñê·Ö•·Ñâ·Ö¶·Ü∫/KEMDy19/annotation'\n",
        "txt_label_zip_toteval_root='/content/gdrive/MyDrive/·ÑÄ·Ö°·Ü∑·Ñå·Ö•·Üº·Ñã·Öµ·Ü´·Ñâ·Öµ·Ü® ·ÑÉ·Ö¢·Ñí·Ö¨/·ÑÉ·Ö¶·Ñã·Öµ·Ñê·Ö•·Ñâ·Ö¶·Ü∫/2019txt_label_zip_toteval.pkl'\n",
        "\n",
        "ambig_annotation=0\n",
        "no_file=0\n",
        "if os.path.isfile(txt_label_zip_toteval_root):\n",
        "  with open(txt_label_zip_toteval_root,'rb') as f:\n",
        "    allfile_datalist=pickle.load(f)\n",
        "else:\n",
        "  allfile_datalist=[]\n",
        "  for i, annotation in tqdm(enumerate(os.listdir(annotation_root))):\n",
        "    all_txts=[]\n",
        "    # print('annotaion file : (%d / %d)'%(i,len(os.listdir(annotation_root))))\n",
        "    session_file = pd.read_csv(os.path.join(annotation_root,annotation)) \n",
        "    # print(session_file) \n",
        "    segments=session_file['Segment ID']\n",
        "    # print(segments)\n",
        "    \n",
        "    for j in range(1,len(segments)):\n",
        "\n",
        "      #index starts from 1\n",
        "      f_name=segments[j]\n",
        "      \n",
        "      # print(\"f_name:\",f_name)\n",
        "      \n",
        "      sess_num=f_name.split('_')[0][-2:]\n",
        "      sc_pro_num=f_name.split('_')[0]+'_'+f_name.split('_')[1]\n",
        "      # print(sess_num,sc_pro_num)\n",
        "      \n",
        "    #  /content/gdrive/MyDrive/·ÑÄ·Ö°·Ü∑·Ñå·Ö•·Üº·Ñã·Öµ·Ü´·Ñâ·Öµ·Ü® ·ÑÉ·Ö¢·Ñí·Ö¨/·ÑÉ·Ö¶·Ñã·Öµ·Ñê·Ö•·Ñâ·Ö¶·Ü∫/KEMDy19/wav/Session01/Sess01_script01/Sess01_script01_F001.txt\n",
        "      file_loc='/content/gdrive/MyDrive/·ÑÄ·Ö°·Ü∑·Ñå·Ö•·Üº·Ñã·Öµ·Ü´·Ñâ·Öµ·Ü® ·ÑÉ·Ö¢·Ñí·Ö¨/·ÑÉ·Ö¶·Ñã·Öµ·Ñê·Ö•·Ñâ·Ö¶·Ü∫/KEMDy19/wav/Session%s/%s/%s.txt'%(sess_num,sc_pro_num,f_name)\n",
        "      # print(file_loc)\n",
        "      if not os.path.isfile(file_loc):\n",
        "        print(\"no file location :\",file_loc)\n",
        "        no_file+=1\n",
        "        continue\n",
        "      with open(file_loc) as f:\n",
        "        lines = f.readlines()\n",
        "        all_txts.append(lines)\n",
        "\n",
        "\n",
        "\n",
        "    session_file.loc[(session_file['Total Evaluation'] == \"fear\"), 'Total Evaluation'] = 0  #Í≥µÌè¨ => 0\n",
        "    session_file.loc[(session_file['Total Evaluation'] == \"surprise\"), 'Total Evaluation'] = 1  #ÎÜÄÎûå => 1\n",
        "    session_file.loc[(session_file['Total Evaluation'] == \"angry\"), 'Total Evaluation'] = 2  #Î∂ÑÎÖ∏ => 2\n",
        "    session_file.loc[(session_file['Total Evaluation'] == \"sad\"), 'Total Evaluation'] = 3  #Ïä¨Ìîî => 3\n",
        "    session_file.loc[(session_file['Total Evaluation'] == \"neutral\"), 'Total Evaluation'] = 4  #Ï§ëÎ¶Ω => 4\n",
        "    session_file.loc[(session_file['Total Evaluation'] == \"happy\"), 'Total Evaluation'] = 5  #ÌñâÎ≥µ => 5\n",
        "    session_file.loc[(session_file['Total Evaluation'] == \"disgust\"), 'Total Evaluation'] = 6  #ÌòêÏò§ => 6\n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "    # print(len(all_txts))\n",
        "    ## zip txts and labels,  session_file start from 1\n",
        "    for q, label in zip(all_txts, session_file['Total Evaluation'][1:])  :\n",
        "      if type(label) is not int :\n",
        "        ambig_annotation+=1\n",
        "        continue\n",
        "      data = []\n",
        "      data.append(q[0])\n",
        "      # print('Q',type(q),q[0])\n",
        "      # print('label',label)\n",
        "      data.append(str(label))\n",
        "      allfile_datalist.append(data)\n",
        "    # print(data_list)\n",
        "    # allfile_datalist.append(data_list)\n",
        "\n",
        "\n",
        "\n",
        "  with open(txt_label_zip_toteval_root,'wb') as f:\n",
        "    pickle.dump(allfile_datalist,f)\n",
        "# print(\"data_list length :\",len(data_list))\n",
        "# print(\"sample : \",data_list[0])\n",
        "  \n",
        "# print(len(all_txts))"
      ],
      "metadata": {
        "id": "SLSTr_rsqjxN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "h3BLdqy7a-j-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7BBac7CPa-gq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LuspU6xca-Ym"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}